<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 周君逸</title>
    <link>/cn/posts/</link>
    <description>Recent content in Posts on 周君逸</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 19 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="/cn/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>纵向数据聚类分析（App）</title>
      <link>/cn/posts/clusterlongapp/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/cn/posts/clusterlongapp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ClusterLong: R-package对于纵向数据（longitudinal data）聚类分析</title>
      <link>/cn/posts/clusterlongpackage/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/cn/posts/clusterlongpackage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>阳性-无标记学习（Positive-and-Unlabeled Learning）</title>
      <link>/cn/posts/pulearning/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/cn/posts/pulearning/</guid>
      <description> 阳性-无标记学习，是指仅观察到阳性标记（记作1）而其余未标记的二元分类问题。 由于未标记的数据部分同时包含0和1，因此如果将无标记部分天真地视为0并执行传统监督学习算法将低估了正例的可能性(Ward et al. 2009; Yang et al. 2012)。但是，如果简单排除这些无标记数据，即在训练集中只有结果为1，却没有结果为0的样本，则无法直接使用已经非常成熟的监督学习方法。 为了克服这一难题，我们将在此讨论PU学习算法。
因为术语过多，请参考英文版。
参考文献 Ward, Gill, Trevor Hastie, Simon Barry, Jane Elith, and John R Leathwick. 2009. “Presence-Only Data and the Em Algorithm.” Biometrics 65 (2): 554–63.
 Yang, Peng, Xiao-Li Li, Jian-Ping Mei, Chee-Keong Kwoh, and See-Kiong Ng. 2012. “Positive-Unlabeled Learning for Disease Gene Identification.” Bioinformatics 28 (20): 2640–7.
   </description>
    </item>
    
    <item>
      <title>OptTrialDesign的逻辑与金融里CAPM的联系</title>
      <link>/cn/posts/odt-capm/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/cn/posts/odt-capm/</guid>
      <description>OptTrialDesign背后的想法 在最优（临床）试验设计中，我们提出了一种寻找最佳实验设计的新颖方法，既可以最大限度地提高财务收益（即预期净收入，ENR），又可以符合监管要求。我们必须在两者中权衡。因为从制药公角度出发，较短的研究期限导致更早的市场准入，这有助于在LOE（排他性损失）之前最大化利润。但另一方面，监管机构和卫生技术评估（HTA）机构希望看到更加有保证的临床结果，这通常需要更长的研究时间。这两者之间存在一定冲突。
在具有time-to-event endpoint的实验中，给定target number of events，临床试验设计仍未完全确定。通常有三个参数，样本量（\(N\)），研究持续时间（\(S\)）和招人速度（\(r_a\)）（或招人时间，如果假设uniform \(r_a\)，在此我们不考虑，也不考虑对于具有中期分析的试验，可以按照类似的想法进行扩展），并且这三者存在无限的组合，从而形成了无数满足条件的试验设计。实际上，\(r_a\)不能取任意数字，因为它受到疾病发病率，类型和场所能力的限制。假设研究人员能够提供大致的\(r_a\)，甚至是一个范围，试验设计的自由度就会从3减少到2，并且我们能够在\(2×2\)平面中展示可行的设计集（如下图所示）。值得注意的是，研究持续时间与样本量之间需要权衡取舍。较大的样本量有助于加快试验，反之亦然。
 金融中的CAPM模型 我们休息一会儿，转向资本资产定价模型（CAPM）。CAPM因其在分析投资组合定价方面的贡献而赢得了1990 年诺贝尔经济学奖，并因其简单性和实用价值而闻名。
在CAPM中，资产或投资组合的预期收益(\(ER_i\))可以通过以下方式计算, \[ ER_i = R_f + \beta_i(ER_m - R_f) \] 其中\(R_f\)是无风险收益率（例如10年期国债收益率）; \(\beta_i\) 代表基于市场风险的个人风险; 以及\(ER_m - R_f\)是市场风险溢价。基本上，这意味着在理想情况下，资产的风险越高，预期的回报就越高。
换句话说，我们可以说为了找到最佳资产，我们实际上需要最大化以下目标函数 \[ \max_i R_f + \beta_i(ER_m - R_f) \text{ for } i \in \text{可行集} \] 那么，什么是可行集？我们知道预期收益会随着资产的预期风险而增加，但是由于边际效用递减，预期收益应该有上限（不能达到无穷大），以及预期风险有下限（不能达到0）。通常，人们认为可行的集合是下图中抛物线所包围的区域。该抛物线（蓝色曲线）称为有效边界，它表示在给定风险下最大和最小的预期收益（注意预期风险和收益的限制）。不在有效边界上资产/投资组合（蓝色圆圈点；请注意，由于有效边界是假设性的，在实践中可能会被违反）是无效区域，因为总是可以在有效边界上找到具有相同预期收益的另一个风险资产，但预期收益更高。
让我们以优化问题的形式重写问题 \[ \begin{aligned} \max_i &amp;amp; \quad R_f + \beta_i(ER_m - R_f) \\ \text{s.t.} &amp;amp; \quad i \in \text{Efficient Frontier} \end{aligned} \] 其中，目标函数\(R_f + \beta_i(ER_m-R_f)\)实际上是资本市场线（capital market line, 图中的黑色直线）。 因此，最佳解决方案是切点（绿点）。</description>
    </item>
    
    <item>
      <title>最优（临床）试验设计（App）</title>
      <link>/cn/posts/opttrialdesignapp/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/cn/posts/opttrialdesignapp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>OptTrialDesign: R-package设计（临床）试验--在最大化收益和监管要求间达到平衡</title>
      <link>/cn/posts/opttrialdesignpackage/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/cn/posts/opttrialdesignpackage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>蒙特卡洛优化</title>
      <link>/cn/posts/mc-opt-slides/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/cn/posts/mc-opt-slides/</guid>
      <description>优化是AI / ML算法的关键组成部分。 无论提出什么目标函数，最后一步都是对其进行优化。 凸优化问题，无论是无约束的还是受约束的，都得到了很好的探讨（请参阅这里）。即使如此，优化效率或性能在很大程度上仍取决于目标函数的表面形状。 对于凸问题（convex optimization problem），解决方案可能会困在鞍点； 或对于局部凸目标函数，解决方案可能会达到局部最优而非全局最优。 当然，尝试使用不同的参数初始值是绕过此问题的一种方法。 在这里，我们介绍了另一种通过蒙特卡洛模拟找到最优值的方法，理论而言，它有机会在任何初始点达到全局最优值。
PDF 文档请点击这里.
相关的报告slides请点击这里.</description>
    </item>
    
  </channel>
</rss>
