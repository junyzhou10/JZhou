<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">
    <meta name="color-scheme" content="light dark">

    

    <meta name="author" content="Junyi Zhou">
    <meta name="description" content="Meta-Learners">
    <meta name="keywords" content="personal, projects, apps">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Meta-Learners (working)"/>
<meta name="twitter:description" content="Meta-Learners"/>

    <meta property="og:title" content="Meta-Learners (working)" />
<meta property="og:description" content="Meta-Learners" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jzhou.org/posts/metalearner/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-02-22T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2022-02-22T00:00:00&#43;00:00" />



    <title>
  Meta-Learners (working) · Junyi Zhou
</title>

    
      <link rel="canonical" href="https://jzhou.org/posts/metalearner/">
    

    <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.1.7" as="font" type="font/woff2" crossorigin>

    
      
      
      <link rel="stylesheet" href="/css/coder.min.406d0bb9b7e93dd1c4497ee4abb177af6bea8f6c16aea89ae05f2aef56ef44e5.css" integrity="sha256-QG0LubfpPdHESX7kq7F3r2vqj2wWrqia4F8q71bvROU=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-dark.min.dde8a61eb31a32353b4baf3d9113f03c4ea2a8ca9bb736f59ca2d2b2cb664f0b.css" integrity="sha256-3eimHrMaMjU7S689kRPwPE6iqMqbtzb1nKLSsstmTws=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    

    <meta name="generator" content="Hugo 0.83.0" />
  </head>

  
  
    
  
  <body class="preload-transitions colorscheme-auto"
        onload=""
  >
    
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Junyi Zhou
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/">Projects</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/publications/">Publications</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/contact/">Contact me</a>
            </li>
          
        
        
          
          
          
            
          
            
              
                <li class="navigation-item menu-separator">
                  <span>|</span>
                </li>
                
              
              <li class="navigation-item">
                <a href="https://jzhou.org/cn/">中文</a>
              </li>
            
          
        
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://jzhou.org/posts/metalearner/">
              Meta-Learners (working)
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime='2022-02-22T00:00:00Z'>
                February 22, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              10-minute read
            </span>
          </div>
          
          <div class="categories">
  <i class="fa fa-folder" aria-hidden="true"></i>
    <a href="/categories/lectures/slides/">Lectures/Slides</a></div>

          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <a href="/tags/causal-inference/">Causal Inference</a></div>

        </div>
      </header>

      <div>
        
        
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>








<div id="TOC">
<ul>
<li><a href="#meta-learners-for-treatment-effect-estimation-optimal-treatment-recommendation-under-multiple-treatment-setting">Meta-learners for treatment effect estimation &amp; optimal treatment recommendation under multiple treatment setting</a><ul>
<li><a href="#treatment-effect-estimation">Treatment Effect Estimation</a><ul>
<li><a href="#q-learning">Q-learning</a></li>
<li><a href="#a-learning">A-learning</a></li>
</ul></li>
<li><a href="#treatment-recommendation">Treatment recommendation</a><ul>
<li><a href="#itr-working">ITR (working)</a></li>
</ul></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<p><em>A corresponding Meta-learner R-package can be found on <a href="https://github.com/junyzhou10/MetaLearners">Github</a> by the same author.</em></p>
<div id="meta-learners-for-treatment-effect-estimation-optimal-treatment-recommendation-under-multiple-treatment-setting" class="section level1">
<h1>Meta-learners for treatment effect estimation &amp; optimal treatment recommendation under multiple treatment setting</h1>
<p>Meta-learners are a simple way to leverage off-the-shelf predictive machine learning methods to estimate CATE/HTE/ITE. A very general process of doing causal inference is provided in the following flowchart, where there are three main parts:</p>
<ol style="list-style-type: decimal">
<li>Understand the real world question: what is the desired causal estimand/quantity. By potential outcome framework along with several assumptions, the causality could be inferred from the observed data.</li>
<li>In step 2, the original real world problem is transformed to a solvable statistical problem with the assumption made in the first step. Usually, there could be different ways to form the statistical problem with pros and cons. As introduced in <a href="https://jzhou.org/posts/reviewcausal/">Review of Causal Inference: An Overview</a>, there are T-learner and S-learner following the Q-learning approach as well as A-learning-based methods such as R-learner and X-learner.</li>
<li>After step 2, the statistical problem is built up, so in step 3, the main focus is how to solve them. If viewing in machine learning perspective, step 2 actually yields a problem specific loss function no matter following Q-learning or A-learning approach. The strength of meta-learners is they do not have strong requirements or limitations on the structure of loss function so that any off-the-shelf base learners can be readily fill in to solve. Such as Random Forests (RF) <span class="citation">(Breiman <a href="#ref-breiman2001random" role="doc-biblioref">2001</a>)</span>, Bayesian Additive Regression Trees (BART) <span class="citation">(Chipman et al. <a href="#ref-chipman2010bart" role="doc-biblioref">2010</a>)</span>, XGBoost <span class="citation">(Chen and Guestrin <a href="#ref-Chen_2016" role="doc-biblioref">2016</a>)</span>, Generalized Additive Model (GAM) <span class="citation">(Hastie and Tibshirani <a href="#ref-hastie1986generalized" role="doc-biblioref">1986</a>)</span>, Neural Network (NN) <span class="citation">(Hopfield <a href="#ref-hopfield1982neural" role="doc-biblioref">1982</a>)</span>, Model-Based recursive partitioning (MOB) <span class="citation">(Zeileis, Hothorn, and Hornik <a href="#ref-zeileis2008model" role="doc-biblioref">2008</a>; Seibold, Zeileis, and Hothorn <a href="#ref-seibold2016model" role="doc-biblioref">2016</a>)</span>, and Super Learner (SL) <span class="citation">(Van der Laan, Polley, and Hubbard <a href="#ref-van2007super" role="doc-biblioref">2007</a>)</span>.</li>
</ol>
<p><img src="/images/ReviewCausal_1.png" /></p>
<hr />
<div id="treatment-effect-estimation" class="section level2">
<h2>Treatment Effect Estimation</h2>
<div id="q-learning" class="section level3">
<h3>Q-learning</h3>
<p>Q-learning gets its name because its objective function plays a role similar to that of the Q or reward function in reinforcement learning <span class="citation">(Sutton and Barto <a href="#ref-sutton2018reinforcement" role="doc-biblioref">2018</a>; Li, Wang, and Tu <a href="#ref-li2021robust" role="doc-biblioref">2021</a>)</span> and is first used in estimating optimal <em>dynamic treatment regime</em> <span class="citation">(Murphy <a href="#ref-murphy2003optimal" role="doc-biblioref">2003</a>; Robins <a href="#ref-robins2004optimal" role="doc-biblioref">2004</a>; Schulte et al. <a href="#ref-schulte2014q" role="doc-biblioref">2014</a>)</span> among causal inference topics. The basic idea is focusing on the estimation of the conditional response surfaces <span class="math inline">\(E[Y \mid \mathbf X, T]\)</span>, which is also known as g-computation <span class="citation">(Robins <a href="#ref-robins1986new" role="doc-biblioref">1986</a>)</span>. So this approach is also called the parametric g-formula <span class="citation">(Hernán and Robins <a href="#ref-hernan2010causal" role="doc-biblioref">2010</a>)</span> in the literature.</p>
<p>Specifically, we here consider Single or S-learner and Two or T-learner method–following the nomenclature in <span class="citation">Künzel et al. (<a href="#ref-kunzel2019metalearners" role="doc-biblioref">2019</a>)</span>, in the Q-learning camp. Both methods can be easily extended to mutliple treatment scenarios.</p>
<div id="s-learner" class="section level4">
<h4>S-learner</h4>
<p>For <strong>S-learner</strong>, we estimate a joint function <span class="math inline">\(\hat\mu(\mathbf X, T) = E[Y \mid \mathbf X, T]\)</span> with <span class="math inline">\(T \in \{1, 2,...,K\}\)</span> then the HTE between treatment <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, <span class="math inline">\(i\neq j\)</span>, can be found by
<span class="math display">\[\begin{equation}
\hat\tau_i^{(j)}(\mathbf X) = \hat\mu(\mathbf X, j) - \hat\mu(\mathbf X, i). \label{eq:Slearner}
\end{equation}\]</span>
The whole data is used to estimate function <span class="math inline">\(\mu()\)</span> but since treatment <span class="math inline">\(T\)</span> is considered as one of the covariates, it can be neglected or underweighted if <span class="math inline">\(X\)</span> has high dimension. In practice, people usually reconstruct the design matrix by <span class="math inline">\([\mathbf X, T, T\cdot \mathbf X]\)</span>, i.e., including the interaction terms to highlight the effects of <span class="math inline">\(T\)</span> <span class="citation">(Lipkovich et al. <a href="#ref-lipkovich2011subgroup" role="doc-biblioref">2011</a>; Tian et al. <a href="#ref-tian2014simple" role="doc-biblioref">2014</a>; Lipkovich, Dmitrienko, and B D’Agostino Sr <a href="#ref-lipkovich2017tutorial" role="doc-biblioref">2017</a>)</span>.</p>
</div>
<div id="t-learner" class="section level4">
<h4>T-learner</h4>
<p><strong>T-learner</strong>, on the other hand, estimate <span class="math inline">\(E[Y \mid \mathbf X, T]\)</span> which only use part of the observed data. For example, when there are <span class="math inline">\(K\)</span> treatments, a total of <span class="math inline">\(K\)</span> functions need to by estimated, i.e., <span class="math inline">\(\mu_k(\mathbf X) = E[Y \mid \mathbf X, T= k]\)</span> for <span class="math inline">\(k=1,...,K\)</span>. Then, the HTE can be calculated by
<span class="math display">\[\begin{equation}
\hat\tau_i^{(j)}(\mathbf X) = \hat\mu_j(\mathbf X) - \hat\mu_{i}(\mathbf X)\label{eq:Tlearner}
\end{equation}\]</span>
But it can lose the data efficiency due to the fact that each model is estimated separately.</p>
</div>
</div>
<div id="a-learning" class="section level3">
<h3>A-learning</h3>
<p>The basic idea of advantage-learning or <strong>A-learning</strong>, is to estimate targeted treatment effect <span class="math inline">\(\tau(\mathbf x)\)</span> directly. The X-learner and R-learner are considered under this framework. Both approaches are initially proposed for two treatments scenario, so we first extend them to multi-arm settings.</p>
<div id="x-learner" class="section level4">
<h4>X-learner</h4>
<p><strong>X-learner</strong> <span class="citation">(Künzel et al. <a href="#ref-kunzel2019metalearners" role="doc-biblioref">2019</a>)</span> enjoys the simplicity of T-learner but fixes its data efficiency issue by targeting on the treatment effects rather than the response surfaces. The main procedure for two-treatment setting is (denote two treatments as <span class="math inline">\(1\)</span> and <span class="math inline">\(-1\)</span>)</p>
<ul>
<li>Step 1: Estimate <span class="math inline">\(\hat\mu_1(\cdot)\)</span> and <span class="math inline">\(\hat\mu_{-1}(\cdot)\)</span> just like T-learner</li>
<li>Step 2a: Impute ITEs for subjects in <span class="math inline">\(T=1\)</span> arm by <span class="math inline">\(\tilde\tau_{1,i} = Y_i - \hat\mu_{-1}(\mathbf x_i)\)</span> (recall that <span class="math inline">\(\tau_i = Y_i^{(1)} - Y_i^{(-1)}\)</span>) and ITEs for subjects in <span class="math inline">\(T=-1\)</span> arm by <span class="math inline">\(\tilde\tau_{-1,i} = \hat\mu_{1}(\mathbf x_i) - Y_i\)</span></li>
<li>Step 2b: Fit one model <span class="math inline">\(\hat\tau_1(\cdot)\)</span> to predict <span class="math inline">\(\tilde\tau_{1,i}\)</span> using data in <span class="math inline">\(T=1\)</span> arm, i.e., <span class="math inline">\(\{(\mathbf x_i, Y_i)\}_{i:T_i = 1}\)</span>; and fit another model <span class="math inline">\(\hat\tau_{-1}(\cdot)\)</span> to predict <span class="math inline">\(\tilde\tau_{-1,i}\)</span> using data in <span class="math inline">\(T=-1\)</span> arm, i.e., <span class="math inline">\(\{(\mathbf x_i, Y_i)\}_{i:T_i = -1}\)</span></li>
<li>Step 3: Combine <span class="math inline">\(\hat\tau_1(\cdot)\)</span> and <span class="math inline">\(\hat\tau_{-1}(\cdot)\)</span> to achieve the final treatment effect model <span class="math inline">\(\hat\tau(\mathbf x) = g(\mathbf x)\tau_{-1}(\mathbf x) + (1-g(\mathbf x))\tau_{1}(\mathbf x)\)</span>, where <span class="math inline">\(g(\cdot)\)</span> is some weighting function, e.g., propensity score.</li>
</ul>
<p>For multi-arm setting, we can extend it with the same gist</p>
<ul>
<li>Step 1: Estimate <span class="math inline">\(\hat\mu_k(\cdot),k=1,...,K\)</span> just like T-learner</li>
<li>Step 2a: For any pairwise HTE, for example, <span class="math inline">\(\tau_i^{(j)}(\mathbf X) = \mathbb E[Y \mid T=j,\mathbf X] - \mathbb E[Y \mid T=i,\mathbf X]\)</span>, we can have two sets of impuations: <span class="math inline">\(\{Y_s - \hat\mu_i(\mathbf X_s)\}_{s:T_s=j}\)</span> and <span class="math inline">\(\{\hat\mu_j(\mathbf X_s) - Y_s\}_{s:T_s=i}\)</span></li>
<li>Step 2b: Fit one model for each imputed HTE which yields two models, denote <span class="math inline">\(\hat\tau_{i,i}^{(j)}(\cdot)\)</span> for <span class="math inline">\(\{Y_s - \hat\mu_i(\mathbf X_s)\}_{s:T_s=j}\)</span> and <span class="math inline">\(\hat\tau_{i,j}^{(j)}(\cdot)\)</span> for <span class="math inline">\(\{\hat\mu_j(\mathbf X_s) - Y_s\}_{s:T_s=i}\)</span></li>
<li>Step 3: Combine <span class="math inline">\(\hat\tau_{i,i}^{(j)}(\cdot)\)</span> and <span class="math inline">\(\hat\tau_{i,j}^{(j)}(\cdot)\)</span> to obtain final estimate <span class="math inline">\(\hat\tau_{i}^{(j)}(\cdot) = g(\cdot)\hat\tau_{i,i}^{(j)}(\cdot) + (1-g(\cdot))\hat\tau_{i,j}^{(j)}(\cdot)\)</span>, where <span class="math inline">\(g(\cdot)\)</span> can be related with estimated propensity scores <span class="math inline">\(g(\cdot)=\hat\pi^{(j)}/(\hat\pi^{(i)}+\hat\pi^{(j)})\)</span></li>
</ul>
<p>One potential issue for X-learner is, the method targets on squared loss function, which means it only applies for continuous outcomes but not for other outcome types.</p>
</div>
<div id="r-learner" class="section level4">
<h4>R-learner</h4>
<p><strong>R-learner</strong> <span class="citation">(Nie and Wager <a href="#ref-NieQuasi2020" role="doc-biblioref">2020</a>)</span> adopts the Robinson’s decomposition <span class="citation">(Robinson <a href="#ref-robinson1988root" role="doc-biblioref">1988</a>)</span> to connect the HTE with the observed outcome
<span class="math display" id="eq:Rlearner">\[\begin{equation}
E[Y\mid \mathbf X, T] = m(\mathbf X) + (1[T = 1]- \pi(\mathbf X))\tau(\mathbf X) \tag{1}
\end{equation}\]</span>
where <span class="math inline">\(m(\mathbf X) = E[Y \mid \mathbf X]\)</span>. Following (citation), the loss function of R-learner for multiple treatment is
<span class="math display" id="eq:rawRL">\[\begin{equation}
\arg\min_{\boldsymbol \tau_i} \ \mathbb E\left[\left( Y - m(\mathbf X) - \sum_{k\neq i} (1[T=k]-\pi^{(k)}(\mathbf X))\tau_i^{(k)}(\mathbf X)\right)^2\right] \tag{2}
\end{equation}\]</span>
where denote the estimated treatment effects <span class="math inline">\(\hat{\boldsymbol \tau}_i = (\hat\tau_i^{(1)},...,\hat\tau_i^{(k-1)}, \hat\tau_i^{(k+1)}, ..., \hat\tau_i^{(K)})\)</span>. In practice, we can estimate <span class="math inline">\(\hat m()\)</span> and <span class="math inline">\(\hat\pi()\)</span> in the first stage and plug in to obtain <span class="math inline">\(\hat{\boldsymbol \tau}_i\)</span>. Notably, with different reference group selection, loss functions <a href="#eq:rawRL">(2)</a> are different so that we can have <span class="math inline">\(K\)</span> sets of estimates: <span class="math inline">\(\hat{\boldsymbol \tau}_1,...,\hat{\boldsymbol \tau}_K\)</span>, which can lead to different HTE estimation as well as the recommendations. In practice, this could raise some concern and limitations.</p>
<p>Similar to X-learner, R-learner is also designed for continuous outcomes due to the squared loss function.</p>
</div>
<div id="reference-free-r-learner" class="section level4">
<h4>Reference-free R-learner</h4>
<p>To deal with the inconsistency recommendation problem in R-learner, the author propose a reference-free R-learner which allows to estimate treatment effect and recommend optimal treatment without specifying a particular reference group. So inconsistency issue is no longer a concern.</p>
<p>(For details, please wait for the publication.)</p>
</div>
<div id="de-centralized-learner" class="section level4">
<h4>de-Centralized-Learner</h4>
<p>(Author proposed method. Easy to use and has superior performance comparing to the other meta-learners.)</p>
<hr />
</div>
</div>
</div>
<div id="treatment-recommendation" class="section level2">
<h2>Treatment recommendation</h2>
<p>For S- and T-learner, the optimal treatment given covariate <span class="math inline">\(\mathbf x\)</span> can be directly derived from
<span class="math display">\[
T^{\text{opt}} = \arg\max_k \hat\mu(\mathbf x, k)
\]</span>
for S-learner and
<span class="math display">\[
T^{\text{opt}} = \arg\max_k \hat\mu_k(\mathbf x)
\]</span>
for T-learner, suppose the larger outcome the better.</p>
<p>Since X-learner returns all possible pairwise treatment comparisons, <span class="math inline">\(\hat\tau_i^{(j)}(\mathbf X)\)</span> for <span class="math inline">\(i=1,...,K\)</span>, <span class="math inline">\(j = 1,...,K\)</span>, and <span class="math inline">\(i \neq j\)</span>, the optimal treatment should be selected with a carefully designed decision rule to handle situations like <span class="math inline">\(\hat\tau_1^{(2)}(\mathbf X) &gt; 0\)</span>, <span class="math inline">\(\hat\tau_2^{(3)}(\mathbf X) &gt; 0\)</span>, and <span class="math inline">\(\hat\tau_3^{(1)}(\mathbf X) &gt; 0\)</span> (given <span class="math inline">\(K=3\)</span>). Here we do not discuss how to choose a proper decision rule for pairwise comparison because it is out of the scope.</p>
<p>For R-learner, given a set of estimated HTE, <span class="math inline">\(\hat{\boldsymbol \tau}_j\)</span>, the optimal treatment can be determined by
<span class="math display">\[
T^{\text{opt}} = 
\begin{cases}
j &amp; \quad \text{if } \hat\tau_j^{(k)}(\mathbf{X})&lt;0 \text{ for } k \neq j,  \\
\arg\max_k \{\hat\tau_j^{(k)}(\mathbf{X}), k = 1,2,...,K\} &amp; \quad \text{else.}
\end{cases}
\]</span>
But as aforementioned, the choice of <span class="math inline">\(j\)</span> leads to different set of <span class="math inline">\(\hat{\boldsymbol \tau}_j\)</span>, and correspondingly, different optimal recommendation <span class="math inline">\(T^{\text{opt}}\)</span>. That is, the selection of treatment group can cause various optimal recommendations.</p>
<hr />
<div id="itr-working" class="section level3">
<h3>ITR (working)</h3>
<p>Other than these learners, the angle-based clutering method by <span class="citation">Qi et al. (<a href="#ref-qi2020multi" role="doc-biblioref">2020</a>)</span> is designed for optimal treatment recommendation with multiple treatments.</p>
<hr />
</div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-breiman2001random">
<p>Breiman, Leo. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1): 5–32.</p>
</div>
<div id="ref-Chen_2016">
<p>Chen, Tianqi, and Carlos Guestrin. 2016. “XGBoost: A Scalable Tree Boosting System.” In <em>Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 785–94. KDD ’16. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/2939672.2939785">https://doi.org/10.1145/2939672.2939785</a>.</p>
</div>
<div id="ref-chipman2010bart">
<p>Chipman, Hugh A, Edward I George, Robert E McCulloch, and others. 2010. “BART: Bayesian Additive Regression Trees.” <em>The Annals of Applied Statistics</em> 4 (1): 266–98.</p>
</div>
<div id="ref-hastie1986generalized">
<p>Hastie, Trevor, and Robert Tibshirani. 1986. “Generalized Additive Models.” <em>Statistical Science</em>, 297–310.</p>
</div>
<div id="ref-hernan2010causal">
<p>Hernán, Miguel A, and James M Robins. 2010. “Causal Inference.” CRC Boca Raton, FL;</p>
</div>
<div id="ref-hopfield1982neural">
<p>Hopfield, John J. 1982. “Neural Networks and Physical Systems with Emergent Collective Computational Abilities.” <em>Proceedings of the National Academy of Sciences</em> 79 (8): 2554–8.</p>
</div>
<div id="ref-kunzel2019metalearners">
<p>Künzel, Sören R, Jasjeet S Sekhon, Peter J Bickel, and Bin Yu. 2019. “Metalearners for Estimating Heterogeneous Treatment Effects Using Machine Learning.” <em>Proceedings of the National Academy of Sciences</em> 116 (10): 4156–65.</p>
</div>
<div id="ref-li2021robust">
<p>Li, Ruohong, Honglang Wang, and Wanzhu Tu. 2021. “Robust Estimation of Heterogeneous Treatment Effects Using Electronic Health Record Data.” <em>Statistics in Medicine</em> 40 (11): 2713–52.</p>
</div>
<div id="ref-lipkovich2017tutorial">
<p>Lipkovich, Ilya, Alex Dmitrienko, and Ralph B D’Agostino Sr. 2017. “Tutorial in Biostatistics: Data-Driven Subgroup Identification and Analysis in Clinical Trials.” <em>Statistics in Medicine</em> 36 (1): 136–96.</p>
</div>
<div id="ref-lipkovich2011subgroup">
<p>Lipkovich, Ilya, Alex Dmitrienko, Jonathan Denne, and Gregory Enas. 2011. “Subgroup Identification Based on Differential Effect Search—a Recursive Partitioning Method for Establishing Response to Treatment in Patient Subpopulations.” <em>Statistics in Medicine</em> 30 (21): 2601–21.</p>
</div>
<div id="ref-murphy2003optimal">
<p>Murphy, Susan A. 2003. “Optimal Dynamic Treatment Regimes.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 65 (2): 331–55.</p>
</div>
<div id="ref-NieQuasi2020">
<p>Nie, X, and S Wager. 2020. “Quasi-oracle estimation of heterogeneous treatment effects.” <em>Biometrika</em> 108 (2): 299–319. <a href="https://doi.org/10.1093/biomet/asaa076">https://doi.org/10.1093/biomet/asaa076</a>.</p>
</div>
<div id="ref-qi2020multi">
<p>Qi, Zhengling, Dacheng Liu, Haoda Fu, and Yufeng Liu. 2020. “Multi-Armed Angle-Based Direct Learning for Estimating Optimal Individualized Treatment Rules with Various Outcomes.” <em>Journal of the American Statistical Association</em> 115 (530): 678–91.</p>
</div>
<div id="ref-robins1986new">
<p>Robins, James. 1986. “A New Approach to Causal Inference in Mortality Studies with a Sustained Exposure Period—Application to Control of the Healthy Worker Survivor Effect.” <em>Mathematical Modelling</em> 7 (9-12): 1393–1512.</p>
</div>
<div id="ref-robins2004optimal">
<p>Robins, James M. 2004. “Optimal Structural Nested Models for Optimal Sequential Decisions.” In <em>Proceedings of the Second Seattle Symposium in Biostatistics</em>, 189–326. Springer.</p>
</div>
<div id="ref-robinson1988root">
<p>Robinson, P. M. 1988. “Root-N-Consistent Semiparametric Regression.” <em>Econometrica</em> 56 (4): 931–54. <a href="http://www.jstor.org/stable/1912705">http://www.jstor.org/stable/1912705</a>.</p>
</div>
<div id="ref-schulte2014q">
<p>Schulte, Phillip J, Anastasios A Tsiatis, Eric B Laber, and Marie Davidian. 2014. “Q-and a-Learning Methods for Estimating Optimal Dynamic Treatment Regimes.” <em>Statistical Science: A Review Journal of the Institute of Mathematical Statistics</em> 29 (4): 640.</p>
</div>
<div id="ref-seibold2016model">
<p>Seibold, Heidi, Achim Zeileis, and Torsten Hothorn. 2016. “Model-Based Recursive Partitioning for Subgroup Analyses.” <em>The International Journal of Biostatistics</em> 12 (1): 45–63.</p>
</div>
<div id="ref-sutton2018reinforcement">
<p>Sutton, Richard S, and Andrew G Barto. 2018. <em>Reinforcement Learning: An Introduction</em>. MIT press.</p>
</div>
<div id="ref-tian2014simple">
<p>Tian, Lu, Ash A Alizadeh, Andrew J Gentles, and Robert Tibshirani. 2014. “A Simple Method for Estimating Interactions Between a Treatment and a Large Number of Covariates.” <em>Journal of the American Statistical Association</em> 109 (508): 1517–32.</p>
</div>
<div id="ref-van2007super">
<p>Van der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1).</p>
</div>
<div id="ref-zeileis2008model">
<p>Zeileis, Achim, Torsten Hothorn, and Kurt Hornik. 2008. “Model-Based Recursive Partitioning.” <em>Journal of Computational and Graphical Statistics</em> 17 (2): 492–514.</p>
</div>
</div>
</div>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      
  <footer class="footer">
    <section class="container">
      
      
        ©
        
          2019 -
        
        2022
         Junyi Zhou 
      
      
         · 
        Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
      
      
        
      
    </section>
  </footer>


    </main>

    
      
      <script src="/js/coder.min.235666b114443867d43eeb5799d51f6252965e5163f338285e113fa381d3d27e.js" integrity="sha256-I1ZmsRREOGfUPutXmdUfYlKWXlFj8zgoXhE/o4HT0n4="></script>
    

    

    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4GM2YKH34F"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-4GM2YKH34F', { 'anonymize_ip': false });
}
</script>


    

    

    

    

    

    
  </body>

</html>
